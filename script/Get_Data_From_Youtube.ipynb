{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JamorMoussa/PFA-/blob/main/script/Get_Data_From_Youtube.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scrape comments from Youtube :"
      ],
      "metadata": {
        "id": "NfyVaB-GLiu1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing libs :    "
      ],
      "metadata": {
        "id": "0NRl0AqML2uW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1k76T9uNLwcH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import requests as rs\n",
        "from bs4 import BeautifulSoup\n",
        "from googleapiclient.discovery import build\n",
        "from pprint import pprint\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Youtube Api Key"
      ],
      "metadata": {
        "id": "vEjadqlrL7di"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_api = \"AIzaSyC3mSypuaR1Cc6m366BS8e5D5UWWTldt9Y\""
      ],
      "metadata": {
        "id": "c56A0lf-7mXE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect :    "
      ],
      "metadata": {
        "id": "ISaPC4s0MAFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "api_service_name = \"youtube\"\n",
        "api_version = \"v3\"\n",
        "DEVELOPER_KEY = my_api\n",
        "\n",
        "youtube = build(api_service_name, api_version, developerKey=DEVELOPER_KEY)"
      ],
      "metadata": {
        "id": "LSdqPzwy7nOZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Search method -> All comment in JSON fromat"
      ],
      "metadata": {
        "id": "ewLtomBYMEtc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search(query=\"chatGpt take jobs\", maxResults=20):\n",
        "  request = youtube.search().list(q=query, type='video', part='id', maxResults=maxResults)\n",
        "  response = request.execute()\n",
        "\n",
        "  size = len(response['items'])\n",
        "  \n",
        "  videoIds = [response['items'][i]['id']['videoId'] for i in range(size)]\n",
        "  video_info = youtube.videos().list(\n",
        "    part='snippet',\n",
        "    id=videoIds\n",
        "  ).execute()\n",
        "\n",
        "  res = [(videoIds[i],\n",
        "          video_info['items'][i]['snippet']['title']) for i in range(size)]\n",
        "  return res"
      ],
      "metadata": {
        "id": "DLQeWG8u_6Rq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract necessary information :     "
      ],
      "metadata": {
        "id": "mxuVyf70MiD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def comment(item, data_dict, cols):\n",
        "  item1 = item[\"snippet\"]\n",
        "\n",
        "  snippet = item1[\"topLevelComment\"][\"snippet\"]\n",
        "\n",
        "  for col in cols:\n",
        "    try:\n",
        "      if col in (\"canReply\",\"totalReplyCount\"):\n",
        "        data_dict[col].append(item1[col])\n",
        "      else: \n",
        "        s = snippet[col]\n",
        "        if s != None and s != 'none':\n",
        "          if col == \"authorChannelId\":\n",
        "            data_dict[col].append(s[\"value\"])\n",
        "          else:\n",
        "            data_dict[col].append(s)\n",
        "\n",
        "        else:\n",
        "          data_dict[col].append(np.nan)\n",
        "    except Exception as e:\n",
        "      data_dict[col].append(np.nan)\n",
        "      raise e\n",
        "\n",
        "  return data_dict"
      ],
      "metadata": {
        "id": "m_DctPKmGZdc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract all comment from one video :    "
      ],
      "metadata": {
        "id": "FQcuchzUMwCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_from_one_video(videoId, max_comments=10000):\n",
        "  cols = [\"videoId\", \"authorChannelId\", \"authorDisplayName\", \"textDisplay\",\n",
        "          \"textOriginal\", \"publishedAt\", \"updatedAt\",\"likeCount\", \"canReply\" ,\"totalReplyCount\"]\n",
        "  data_dict = {col : [] for col in cols}\n",
        "\n",
        "  request = youtube.commentThreads().list(\n",
        "          part=\"snippet\",\n",
        "          videoId=videoId,\n",
        "          textFormat=\"plainText\",\n",
        "          maxResults=max_comments,\n",
        "          order='time'\n",
        "   )\n",
        "\n",
        "  response = request.execute()\n",
        "  while response:\n",
        "      for item in response[\"items\"]:\n",
        "        data_dict = comment(item, data_dict, cols)\n",
        "      if 'nextPageToken' in response:\n",
        "          request = youtube.commentThreads().list(\n",
        "              part=\"snippet\",\n",
        "              videoId=videoId,\n",
        "              textFormat=\"plainText\",\n",
        "              maxResults=max_comments,\n",
        "              order='time',\n",
        "              pageToken=response['nextPageToken']\n",
        "          )\n",
        "          response = request.execute()\n",
        "      else:\n",
        "          break\n",
        "  return pd.DataFrame(data_dict)"
      ],
      "metadata": {
        "id": "94tpXMGPD1eS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract all comment from all videos :    "
      ],
      "metadata": {
        "id": "Z8XEVy9-M2Ss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_comments_from_all_videos(search_word = 'chatgpt take jobs', max_video=10):\n",
        "  try: \n",
        "    os.mkdir('/content/data/')\n",
        "  except:\n",
        "    pass\n",
        "  res = search(search_word, max_video)\n",
        "  for i, r in enumerate(res):\n",
        "    try:\n",
        "      videoId, title = r\n",
        "      print('\\nTitle : ',title,'\\n')\n",
        "      ans = input('continue with this video ? : ').lower()\n",
        "\n",
        "      if ans=='y':\n",
        "        data = get_data_from_one_video(videoId)\n",
        "\n",
        "        data.to_csv(f'/content/data/{title}.csv')\n",
        "\n",
        "        print(f'\\n data of video {i+1} is created\\n')\n",
        "      elif ans == 'n':\n",
        "        pass\n",
        "      else:\n",
        "        return\n",
        "    except:\n",
        "      pass\n"
      ],
      "metadata": {
        "id": "3rSl-SnDAr1F"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## search for : Chatgpt will take jobs?"
      ],
      "metadata": {
        "id": "0xaUMmmnM8go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_comments_from_all_videos(search_word=\"chatgpt take jobs\", max_video=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feB0LynXOVvZ",
        "outputId": "4fedec4e-87bf-42f0-896b-547b73d0b275"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Title :  Will ChatGPT Take Your Job? \n",
            "\n",
            "continue with this video ? : y\n",
            "\n",
            " data of video 1 is created\n",
            "\n",
            "\n",
            "Title :  The rise of AI: Could ChatGPT take your job? \n",
            "\n",
            "continue with this video ? : y\n",
            "\n",
            " data of video 2 is created\n",
            "\n",
            "\n",
            "Title :  3 Jobs Chat GPT Will Fully Replace \n",
            "\n",
            "continue with this video ? : y\n",
            "\n",
            " data of video 3 is created\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combine all csv file in one file :    "
      ],
      "metadata": {
        "id": "dSAEuxJLNPDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataframes= []\n",
        "for i, file in enumerate(os.listdir('/content/data')):\n",
        "  try:\n",
        "    dataframes.append(pd.read_csv(os.path.join('/content/data/',file)))\n",
        "  except:\n",
        "    pass\n",
        "data = pd.concat(dataframes)"
      ],
      "metadata": {
        "id": "GY_cGgnDVwVb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.to_csv('/content/All_Dataset.csv')"
      ],
      "metadata": {
        "id": "E8HlSXVqW4-9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x0lbucaqPvJ7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}